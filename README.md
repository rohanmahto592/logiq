# ğŸªµ **LogIQ â€” Intelligent Log Scanner, Analyzer & Dashboard**

### *Fast. Automated. DuckDB Powered.*

<p align="center">
  <img src="https://img.shields.io/badge/Go-1.22+-00ADD8?logo=go&logoColor=white" />
  <img src="https://img.shields.io/badge/Python-3.9+-3776AB?logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/DuckDB-0.10+-FFF000?logo=duckdb&logoColor=black" />
  <img src="https://img.shields.io/badge/Streamlit-1.x-FF4B4B?logo=streamlit&logoColor=white" />
  <img src="https://img.shields.io/badge/Parquet-Optimized-0E7AFE?logo=apache" />
  <img src="https://img.shields.io/badge/License-MIT-green" />
</p>

---

# ğŸ“Œ **Overview**

**LogIQ** is a high-performance log Intelligence platform that:

âœ”ï¸ Scans logs from files or directories
âœ”ï¸ Extracts timestamps, file paths, and metadata
âœ”ï¸ Converts logs â†’ JSON â†’ Parquet
âœ”ï¸ Loads them into **DuckDB** for instant analytics
âœ”ï¸ Detects anomalies using rule-based analysis
âœ”ï¸ Generates JSON + HTML reports
âœ”ï¸ Includes a full **Streamlit dashboard** with SQL query editor and visualizations

It is built in **Go + Python**, optimized for **sub-second querying** of millions of log rows.

---

# ğŸ“‚ Project Architecture

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚          Log Sources           â”‚
                 â”‚  *.log  / app logs / system    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚        Go Log Scanner (scanner/)         â”‚
             â”‚  âœ“ Pattern filters                       â”‚
             â”‚  âœ“ Timestamp extraction                  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      JSON Convertor         â”‚     â”‚       Parquet Writer       â”‚
        â”‚ jsonConvertor/              â”‚     â”‚ parquetwriter/             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ DuckDB Query Engine  â”‚
                   â”‚    queryengine/      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚      Streamlit Dashboard (ui/)        â”‚
             â”‚  âœ“ SQL Query editor                   â”‚
             â”‚  âœ“ Charts / Heatmaps                  â”‚
             â”‚  âœ“ CSV Export                         â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“ Folder Structure

```
logiq/
â”‚â”€â”€ cmd/
â”‚     â””â”€â”€ main.go
â”‚
â”‚â”€â”€ pkg/
â”‚     â”œâ”€â”€ scanner/              # Reads & filters logs
â”‚     â”œâ”€â”€ jsonConvertor/        # Saves logs as JSON
â”‚     â”œâ”€â”€ parquetwriter/        # Converts JSON â†’ Parquet
â”‚     â”œâ”€â”€ analyzer/             # Anomaly detection
â”‚     â”œâ”€â”€ reporter/             # HTML/JSON report generation
â”‚     â”œâ”€â”€ config/               # YAML config loader
â”‚     â””â”€â”€ ...
â”‚
â”‚â”€â”€ queryengine/
â”‚     â””â”€â”€ engine.py             # DuckDB Parquet engine
â”‚
â”‚â”€â”€ ui/
â”‚     â””â”€â”€ main.py               # Streamlit dashboard
â”‚
â”‚â”€â”€ configs/
â”‚     â””â”€â”€ logiq.yaml            # Main configuration file
â”‚
â”‚â”€â”€ logs/                       # Incoming log files
â”‚â”€â”€ jsonLogs/                   # Temporary JSON storage
â”‚â”€â”€ mnt/data/logiq/parquet/     # Parquet output
â”‚â”€â”€ reports/                    # Generated reports
â”‚
â””â”€â”€ README.md
```

---

# âš™ï¸ Installation

### **1. Clone the repo**

```bash
git clone https://github.com/yourname/logiq.git
cd logiq
```

---

# ğŸ“¦ Dependencies

### **Go**

```bash
go mod tidy
```

### **Python (Streamlit UI + DuckDB)**

```bash
pip install -r requirements.txt
```

Recommended packages:

```
duckdb
streamlit
pandas
altair
```

---

# ğŸš€ Running LogIQ

## âœ… **1. Manual Scan**

```bash
go run cmd/main.go --scan=true --report=true
```

## ğŸ” **2. Scheduled Scan (every X seconds)**

Configured in `logiq.yaml`

```bash
go run cmd/main.go
```

---

# ğŸ›  Configuration (`configs/logiq.yaml`)

```yaml
log_paths:
  - "./logs/*.log"

include_patterns:
  - "(?i)ERROR"
  - "(?i)WARN"
  - "(?i)CRITICAL"

exclude_patterns:
  - "(?i)DEBUG"

timestamp_patterns:
  - "\\d{4}-\\d{2}-\\d{2}[ T]\\d{2}:\\d{2}:\\d{2}"
  - "[A-Z][a-z]{2} [0-9]{1,2} [0-9:]{8}"
  - "\\d{2}/[A-Z][a-z]{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2}"

alert_rules:
  - keyword: "(?i)ERROR"
    severity: "high"
  - keyword: "(?i)timeout"
    severity: "medium"

output:
  format: "json,html"
  report_file: "reports/logiq-report.json"

analysis:
  group_by: "keyword"
  threshold_spike: 50
  interval_seconds: 10

output_paths:
  parquet_dir_path: "mnt/data/logiq/parquet/"
  json_dir_path: "jsonLogs/"
```

---

# ğŸ“Š Streamlit Dashboard (UI)

Launch:

```bash
streamlit run ui/main.py
```

---

# ğŸ–¼ Dashboard Features

### âœ” SQL Query Editor

### âœ” Last 100 logs / last 100 errors

### âœ” Bar chart â€” Severity

### âœ” Line chart â€” Logs over Time

### âœ” Heatmap â€” File vs Severity

### âœ” Auto severity classification

### âœ” CSV export

### âœ” Auto schema detection

### âœ” Highlighted logs table (color-coded)

---

# ğŸ§  Sample SQL Queries

Fetch logs from Feb 2025:

```sql
SELECT * FROM logs 
WHERE DATE(timestamp) BETWEEN '2025-02-01' AND '2025-02-28';
```

Count daily errors:

```sql
SELECT DATE(timestamp) AS day, COUNT(*) 
FROM logs 
WHERE severity = 'ERROR'
GROUP BY day;
```

Find slow requests:

```sql
SELECT * FROM logs 
WHERE content LIKE '%timeout%' OR content LIKE '%slow%';
```

---

# ğŸ“„ Reports

Reports generated in:

```
reports/logiq-report.json
reports/logiq-report.html
```

Contains:

* Error distribution
* Spike detection
* Timeline graphs
* Keyword-level grouping

---

# ğŸ§ª Parquet Query Performance

DuckDB can query:

* **1 million rows â†’ < 200ms**
* **10 million rows â†’ < 1s**

Tested using:

```sql
SELECT COUNT(*) FROM logs;
```

---

# ğŸ§© Example Go Runner (Main Loop)

```go
ticker := time.NewTicker(time.Duration(intervalSeconds) * time.Second)
for {
    executeProcess(cfg, true)
    <-ticker.C
}
```

---

# ğŸ”® Future Enhancements

* Machine Learning anomaly detection
* Distributed log collectors
* Slack / Email alerting
* Kubernetes operator integration
* Kafka ingestion
* Real-time dashboards

---

# ğŸ¤ Contributing

PRs are welcome!
Please follow Go formatting and PEP-8 for Python.

---
